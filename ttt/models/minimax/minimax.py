# minimax.py

# Import the MCBoard class that is just the same as the class Board.
# Inside a package, relative path is valid.
from .mm_board import MMBoard
# import the MMData class to save the data generated by Minimax Algorithm.
from .mm_data import MMData

import copy, math

class Minimax:
    """Finds the optimal action for AI using minimax algorithm."""
    
    def __init__(self, initial_state, user_agent):
        # Get information about the board and the user.
        self.initial_state = initial_state
        # print(f'Board State: {self.board_state}')
        self.user_agent = user_agent
        self.ai_agent = -1 if self.user_agent == 1 else 1 
        # self.ai_agent = - self.user_agent # user_agent is 1 or -1.
        # Initialize the ai_move: This is the final goal for this Monte Carlo simulation to achieve.
        self.ai_move = (None, None) 

    # Find empty tiles on the board or all possible actions for AI to take.
    def find_actions(self, board_state):
        actions = [] # List of coordinates (i, j)
        
        for i, row in enumerate(board_state):
            for j, element in enumerate(row):
                if element == 0:
                    actions.append((i, j))
        return actions

    def find_child_state(self, state, action, maximizer):
        result = copy.deepcopy(state)
        i, j = action
        result[i][j] = 1 if maximizer else -1
        return result

            
    # --------------------------------------------------------------
    # Perform minimax algorithm for AI: without alpha-beta Prunning.
    # --------------------------------------------------------------
    def perform_minimax(self):
        # Find empty tiles or all possible actions for AI to take.
        self.initial_actions = self.find_actions(self.initial_state)
        # Define depth: the number of moves required to fill the board completely.
        self.depth_max = len(self.initial_actions)
        # Check if ai_agent is the maximizer or minimizer.
        self.maximizer = True if self.ai_agent == 1 else False # minimax works for AI.
        #
        # Create an instance of MMData to save the outcome obtained from minimax algorithm.
        # Its self.outcome has the form of {(0, 0): 0, (0, 1): 0, ... },
        # where the key (0, 0) stands for an emptry tile and its value is the outcome of minimax algorithm.
        self.data = MMData(self.initial_actions)
        # self.outcome_sorted = {} # sorted self.outcome is in a descending order for the case of maximizer.
        # self.game_record = [] # Each game record can be stored: [(1, 1), (0, 0), (2, 0), (0, 2), (0, 1), ...].
        #
        print(f'Minimax runs with depth: {self.depth_max}') 
        #
        # set a counter to check how many states examined.
        self.backtracking_counter = 0
        #
        # Performs minimax algorithm for AI to find the value of the current state.
        # If AI is the maximizer, the minimax function returns the possible actions and their values in a dictionary.
        # Perform Minimax algorithm without alpha-beta prunning.
        # self.minimax(self.initial_state, self.maximizer)
        # ------------------------------------------------------------------
        # Perform Minimax algorithm #1: with alpha-beta prunning: Wikipedia
        # ------------------------------------------------------------------
        # Warning: This algorithm doesn't work properly.
        # self.alpha = -math.inf
        # self.beta = +math.inf
        # self.minimax(self.initial_state, self.alpha, self.beta, self.maximizer)
        # self.data.generate_outcome(self.maximizer)
        # self.ai_move = self.data.ai_move
        # ---------------------------------------------------------------
        # Minimax algorithm #2: With alpha-beta pruning: CS50 AI Harvard
        # ---------------------------------------------------------------
        self.ai_move = self.minimax(self.initial_state, self.maximizer)
        #
        print(f'Minimax done!')
        print(f'maximum depth: {self.depth_max}')
        print(f'AI is maximizer? {self.maximizer}')
        print(f'backtracking counter: {self.backtracking_counter}')
        print(f'initial state: {self.initial_state}')
        print(f'initial actions: {self.initial_actions}')
        print(f'outcomes: {self.data.outcome}')
        
    # -----------------------------------------------------------------------------    
    # Perform minimax algorithm for AI: with Alpha-Beta Prunning from Wikipedia
    # ----------------------------------------------------------------------------- 
    # def minimax(self, state, alpha, beta, maximizingPlayer):
        
    #     actions = self.find_actions(state)
    #     depth = len(actions)
    #     board = MMBoard(self.user_agent)
    #     board.update(state)
        
    #     if depth == 0 or board.game_over:
    #         return board.score
    
    #     if maximizingPlayer:
    #         value = - math.inf
    #         for action in actions:
    #             child_state = self.find_child_state(state, action, maximizer=True)
    #             value = max(value, self.minimax(child_state, alpha, beta, False))
    #             if depth == self.depth_max:
    #                 self.data.outcome[action] = value
    #             if value >= beta: 
    #                 break 
    #             alpha = max(alpha, value)
    #         return value
    #     else:
    #         value = + math.inf
    #         for action in actions:
    #             child_state = self.find_child_state(state, action, maximizer=False)
    #             value = min(value, self.minimax(child_state, alpha, beta, True))
    #             if depth == self.depth_max:
    #                 self.data.outcome[action] = value
    #             if value <= beta: 
    #                 break 
    #             beta = min(beta, value)
    #         return value
    
    # -----------------------------------------------------------------------------    
    # Perform minimax algorithm for AI: with Alpha-Beta Prunning: Harvard CS50 AI.
    # -----------------------------------------------------------------------------   
    # The source codes of minimax algorithm below comes from the course of CS50: AI at Havard university.
    # I kept its logic but modified some lines of the codes: variable's names and evaluation function and so on.
    def max_value(self, state, alpha, beta):
        """
        Returns the maximum value for the current player on the board 
        using alpha-beta pruning.
        """
        actions = self.find_actions(state)
        board = MMBoard(self.user_agent)
        board.update(state)
        
        if board.game_over:
            return board.score
        
        v = -math.inf
        for action in actions:
            child_state = self.find_child_state(state, action, maximizer=True)
            v = max(v, self.min_value(child_state, alpha, beta))
            alpha = max(alpha, v)
            if alpha >= beta:
                break
        return v

    def min_value(self, state, alpha, beta):
        """
        Returns the minimum value for the current player on the board 
        using alpha-beta pruning.
        """
        actions = self.find_actions(state)
        board = MMBoard(self.user_agent)
        board.update(state)
        
        if board.game_over:
            return board.score
        
        v = math.inf
        for action in actions:
            child_state = self.find_child_state(state, action, maximizer=False)
            v = min(v, self.max_value(child_state, alpha, beta))
            beta = min(beta, v)
            if alpha >= beta:
                break
        return v

    def minimax(self, state, maximizer):
        """
        Returns the optimal action for the current player on the board 
        using the minimax algorithm with alpha-beta pruning.
        """
        actions = self.find_actions(state)
        board = MMBoard(self.user_agent)
        board.update(state)
        depth = len(actions)
        
        if board.game_over:
            return None

        if maximizer:
            v = -math.inf
            optimal_action = None
            for action in actions:
                child_state = self.find_child_state(state, action, maximizer=True)
                new_value = self.min_value(child_state, -math.inf, math.inf)
                if depth == self.depth_max:
                    self.data.outcome[action] = new_value
                if new_value > v:
                    v = new_value
                    optimal_action = action
            return optimal_action
        
        else:
            v = math.inf
            optimal_action = None
            for action in actions:
                child_state = self.find_child_state(state, action, maximizer=False)
                new_value = self.max_value(child_state, -math.inf, math.inf)
                if depth == self.depth_max:
                    self.data.outcome[action] = new_value
                if new_value < v:
                    v = new_value
                    optimal_action = action
            return optimal_action
    